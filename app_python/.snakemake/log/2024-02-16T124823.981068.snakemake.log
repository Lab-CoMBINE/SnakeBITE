Building DAG of jobs...
Retrieving input from storage.
Using shell: /usr/bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job stats:
job               count
--------------  -------
minimap2              1
samtools_index        1
samtools_sort         1
snv_clair3            1
total                 4

Select jobs to execute...
Execute 1 jobs...

[Fri Feb 16 12:48:24 2024]
localrule minimap2:
    input: /data2/utility/references/genomics/hs37d5.decoy.fa, /data2/mbaragli/python_app/app_python/work_dir/data/samples/A.fastq
    output: /data2/mbaragli/python_app/app_python/work_dir/prv_local/mapped_reads/prv_local.bam
    jobid: 2
    reason: Missing output files: /data2/mbaragli/python_app/app_python/work_dir/prv_local/mapped_reads/prv_local.bam
    wildcards: sample=prv_local
    resources: tmpdir=/tmp

[Fri Feb 16 12:50:23 2024]
Finished job 2.
1 of 4 steps (25%) done
Select jobs to execute...
Execute 1 jobs...

[Fri Feb 16 12:50:23 2024]
localrule samtools_sort:
    input: /data2/mbaragli/python_app/app_python/work_dir/prv_local/mapped_reads/prv_local.bam
    output: /data2/mbaragli/python_app/app_python/work_dir/prv_local/sorted_reads/prv_local_sorted.bam
    jobid: 1
    reason: Missing output files: /data2/mbaragli/python_app/app_python/work_dir/prv_local/sorted_reads/prv_local_sorted.bam; Input files updated by another job: /data2/mbaragli/python_app/app_python/work_dir/prv_local/mapped_reads/prv_local.bam
    wildcards: sample=prv_local
    resources: tmpdir=/tmp

[Fri Feb 16 12:50:24 2024]
Finished job 1.
2 of 4 steps (50%) done
Select jobs to execute...
Execute 1 jobs...

[Fri Feb 16 12:50:24 2024]
localrule samtools_index:
    input: /data2/mbaragli/python_app/app_python/work_dir/prv_local/sorted_reads/prv_local_sorted.bam
    output: /data2/mbaragli/python_app/app_python/work_dir/prv_local/sorted_reads/prv_local_sorted.bam.bai
    jobid: 3
    reason: Missing output files: /data2/mbaragli/python_app/app_python/work_dir/prv_local/sorted_reads/prv_local_sorted.bam.bai; Input files updated by another job: /data2/mbaragli/python_app/app_python/work_dir/prv_local/sorted_reads/prv_local_sorted.bam
    wildcards: sample=prv_local
    resources: tmpdir=/tmp

[Fri Feb 16 12:50:24 2024]
Finished job 3.
3 of 4 steps (75%) done
Select jobs to execute...
Execute 1 jobs...

[Fri Feb 16 12:50:24 2024]
localrule snv_clair3:
    input: /data2/utility/references/genomics/hs37d5.decoy.fa, /data2/mbaragli/python_app/app_python/work_dir/prv_local/sorted_reads/prv_local_sorted.bam, /data2/mbaragli/python_app/app_python/work_dir/prv_local/sorted_reads/prv_local_sorted.bam.bai
    output: /data2/mbaragli/python_app/app_python/work_dir/prv_local/snv/prv_local_clair3
    jobid: 0
    reason: Missing output files: /data2/mbaragli/python_app/app_python/work_dir/prv_local/snv/prv_local_clair3; Input files updated by another job: /data2/mbaragli/python_app/app_python/work_dir/prv_local/sorted_reads/prv_local_sorted.bam, /data2/mbaragli/python_app/app_python/work_dir/prv_local/sorted_reads/prv_local_sorted.bam.bai
    wildcards: sample=prv_local
    resources: tmpdir=/tmp

Activating conda environment: nano_clair3
ImproperOutputException in rule snv_clair3 in file /data2/mbaragli/python_app/app_python/Snakefile, line 147:
Outputs of incorrect type (directories when expecting files or vice versa). Output directories must be flagged with directory(). for rule snv_clair3:
    output: /data2/mbaragli/python_app/app_python/work_dir/prv_local/snv/prv_local_clair3
    wildcards: sample=prv_local
    affected files:
        /data2/mbaragli/python_app/app_python/work_dir/prv_local/snv/prv_local_clair3
Removing output files of failed job snv_clair3 since they might be corrupted:
/data2/mbaragli/python_app/app_python/work_dir/prv_local/snv/prv_local_clair3
Skipped removing non-empty directory /data2/mbaragli/python_app/app_python/work_dir/prv_local/snv/prv_local_clair3
Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: .snakemake/log/2024-02-16T124823.981068.snakemake.log
WorkflowError:
At least one job did not complete successfully.
