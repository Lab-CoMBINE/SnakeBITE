Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job stats:
job       count
------  -------
dorado        1
total         1

Select jobs to execute...
Execute 1 jobs...

[Wed Apr 24 14:16:40 2024]
localrule dorado:
    input: /data2/mbaragli/python_app/app_python/extra_files/A.sam
    output: /data2/mbaragli/python_app/app_python/work_dir/A/mapped_reads/A.bam
    jobid: 0
    reason: Missing output files: /data2/mbaragli/python_app/app_python/work_dir/A/mapped_reads/A.bam
    wildcards: sample=A
    resources: tmpdir=/tmp

/data1/Tools/lib/dorado-0.5.0-linux-x64/bin/dorado basecaller /data2/mbaragli/Desumma/ /data2/mbaragli/python_app/app_python/extra_files/A.sam    > /data2/mbaragli/python_app/app_python/work_dir/A/mapped_reads/A.bam
[Wed Apr 24 14:16:44 2024]
Error in rule dorado:
    jobid: 0
    input: /data2/mbaragli/python_app/app_python/extra_files/A.sam
    output: /data2/mbaragli/python_app/app_python/work_dir/A/mapped_reads/A.bam
    shell:
        /data1/Tools/lib/dorado-0.5.0-linux-x64/bin/dorado basecaller /data2/mbaragli/Desumma/ /data2/mbaragli/python_app/app_python/extra_files/A.sam    > /data2/mbaragli/python_app/app_python/work_dir/A/mapped_reads/A.bam
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Removing output files of failed job dorado since they might be corrupted:
/data2/mbaragli/python_app/app_python/work_dir/A/mapped_reads/A.bam
Exiting because a job execution failed. Look above for error message
Complete log: .snakemake/log/2024-04-24T141640.221475.snakemake.log
WorkflowError:
At least one job did not complete successfully.
